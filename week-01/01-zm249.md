# LLM-01-资料搜集

## LLaMa

作者：看图学
链接：https://www.zhihu.com/question/608820310/answer/3091336166
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



## **Stage1 预训练: LLaMA 复现**

### **RedPajama**

- 参考LLaMA论文中的训练数据，收集并且开源可商用。
- [https://github.com/togethercomputer/RedPajama-Data](https://link.zhihu.com/?target=https%3A//github.com/togethercomputer/RedPajama-Data)



### **Baichuan-7B(支持中文)**

- 采用LLaMA的相同架构，在中文上做预训练。可商用。
- [王小川](https://www.zhihu.com/search?q=王小川&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A3091336166})这次做大模型的切入点其实挺不错的，绑定到LLaMA的生态上，然后在中文上有所突破。可能也在构思新[三级火箭](https://www.zhihu.com/search?q=三级火箭&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A3091336166})了吧。
- 目前Baichuan可以算是第一个LLaMA中文预训练模型，所以**后面的工作都可以在这上面都走一遍**，估计没多久Baichuan-Alapca, Baichuan-Vicuna就都出来了。
- [https://github.com/baichuan-inc/baichuan-7B](https://link.zhihu.com/?target=https%3A//github.com/baichuan-inc/baichuan-7B)



### **OpenLLaMA**

- 参考LLaMA的代码，在Apache 2.0 license下的重新实现和训练。使用了RedPajama训练集合。
- [https://github.com/openlm-research/open_llama](https://link.zhihu.com/?target=https%3A//github.com/openlm-research/open_llama)



### **Lit-LLaMA ️**

- 参考LLaMA，在Apache 2.0 license下的只有代码的重新实现。同时支持加载原始LLaMA和OpenLLaMA的权重。
- [https://github.com/Lightning-AI/lit-llama](https://link.zhihu.com/?target=https%3A//github.com/Lightning-AI/lit-llama)



## **Stage 2: 监督微调**

因为预训练模型本质上还是个续写模型，所以并不能很好的满足人们的需求，所以监督微调的作用就是微调模型产生理想的回复。

在监督微调这里，大家目标都是一样的，但是做法有些不同，主要是有钱和没钱的区别。

有钱你可以[全参数微调](https://www.zhihu.com/search?q=全参数微调&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A3091336166})，没钱就只能使用一些低成本的方法，英文叫PEFT(Parameter-Efficient Fine-Tuning)。

PEFT确实是想我这种平民玩家的首选，但是有钱也可以用PEFT，它可以让你微调更大的模型。比如我们就只能玩玩10B的，有点小钱用PEFT玩个几十B的问题不大。



### **2.1 LLaMA + Instruction Finetuning(全量参数)**



#### **Alpaca**

- llama7b + self-instruct数据指令微调。算是最早迈出LLaMA+SFT这一步的模型。最开始并没有提供权重，后来通过diff的方式给出，需要LLaMA原始模型才能恢复，github上有教程。
- 当时他们采用1张8卡A100(80G显存)，52k的数据，训练了3个小时。训练成本大概是100刀。
- [https://github.com/tatsu-lab/stanford_alpaca](https://link.zhihu.com/?target=https%3A//github.com/tatsu-lab/stanford_alpaca)

#### **Alpaca衍生模型**

- BELLE(支持中文): 最早是基于BLOOM的，后来也支持LLaMA [https://github.com/LianjiaTech/BELLE](https://link.zhihu.com/?target=https%3A//github.com/LianjiaTech/BELLE)
- openAlpaca: OpenLLaMA + databricks-dolly-15k dataset 进行指令微调 [https://github.com/yxuansu/OpenAlpaca](https://link.zhihu.com/?target=https%3A//github.com/yxuansu/OpenAlpaca)
- gpt4-x-alpaca: 用GPT4的数据微调，数据集为GPTeacher [https://huggingface.co/chavinlo/gpt4-x-alpaca](https://link.zhihu.com/?target=https%3A//huggingface.co/chavinlo/gpt4-x-alpaca)



#### **Vicuna**

- llama13b + ShareGPT对话数据，微调
- 研发团队基于Vicuna发布了FastChat对话机器人。
- 和Alpaca一样，受协议限制，vicuna模型公布的权重也是个delta，每个参数要加上llama原来的权重才是模型权重。
- [https://github.com/lm-sys/FastChat](https://link.zhihu.com/?target=https%3A//github.com/lm-sys/FastChat)

#### **Vicuna衍生模型**

- gpt4-x-vicuna-13b: 用GPT4的数据微调，数据集为GPTeacher [https://huggingface.co/NousResearch/gpt4-x-vicuna-13b](https://link.zhihu.com/?target=https%3A//huggingface.co/NousResearch/gpt4-x-vicuna-13b)



#### **WizardLM**

- 采用了[Evol-Instruct](https://www.zhihu.com/search?q=Evol-Instruct&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A3091336166})来构造指令，可以产生一些很难的指令.

1. 深度演化包括五种操作：添加约束、深化、具体化、增加推理步骤并使输入复杂化。
2. In-breadth Evolving 是突变，即根据给定的指令生成全新的指令
3. 进化是通过提示+LLM来实现的。

[https://github.com/nlpxucan/WizardLM](https://link.zhihu.com/?target=https%3A//github.com/nlpxucan/WizardLM)



#### **TÜLU**

- 使用LLaMA + Human/GPT data mix 微调
- 验证了很多结论，论文值得一看。[https://arxiv.org/abs/2306.04751](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2306.04751)
- [https://github.com/allenai/open-instruct](https://link.zhihu.com/?target=https%3A//github.com/allenai/open-instruct)



#### **GPT4ALL**

- LLaMA用80w的[GPT3.5](https://www.zhihu.com/search?q=GPT3.5&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A3091336166})的数据(code, story, conversation)微调而来。
- [https://github.com/nomic-ai/gpt4all](https://link.zhihu.com/?target=https%3A//github.com/nomic-ai/gpt4all)



#### **Koala**

- LLaMA13B基于ChatGPT Distillation Data和Open Source Data训练而来。

- 具体数据见下面：

- - [https://bair.berkeley.edu/blog/2023/04/03/koala/](https://link.zhihu.com/?target=https%3A//bair.berkeley.edu/blog/2023/04/03/koala/)



#### **OpenBuddy(支持中文)**

- 基于LLaMA，Falcon, OpenLLaMA微调的，只说用了对话数据，细节没透漏。
- [https://github.com/OpenBuddy/OpenBuddy](https://link.zhihu.com/?target=https%3A//github.com/OpenBuddy/OpenBuddy)



#### **Pygmalion 7B**

- 给予LLaMA微调，使用了不同来源的56MB 的对话数据，包含了人工和机器。
- [https://huggingface.co/PygmalionAI/pygmalion-7b](https://link.zhihu.com/?target=https%3A//huggingface.co/PygmalionAI/pygmalion-7b)

